{
  "dataset_reader": {
    "type": "classification",
    "token_indexers": {
      "bert": {
          "type": "bert-pretrained",
          "pretrained_model": "data/embedding/bert/vocab.txt",
          "do_lowercase": false,
          "use_starting_offsets": true
      },
      "token_characters": {
        "type": "characters",
        "min_padding_length": 3
      }
    }
   },
  "train_data_path": "data/news_classification/bd_train1.txt",
  "validation_data_path": "data/news_classification/bd_val1.txt",

  "model": {
    "type": "c_bcn",
    "text_field_embedder": {
        "allow_unmatched_keys": true,
        "embedder_to_indexer_map": {
            "bert": ["bert", "bert-offsets"],
            "token_characters": ["token_characters"]
        },
        "token_embedders": {
            "bert": {
                "type": "bert-pretrained",
                "pretrained_model": "data/embedding/bert/bert-base-chinese.tar.gz"
            },
            "token_characters": {
                "type": "character_encoding",
                "embedding": {
                    "embedding_dim": 16
                },
                "encoder": {
                    "type": "cnn",
                    "embedding_dim": 16,
                    "num_filters": 128,
                    "ngram_filter_sizes": [3],
                    "conv_layer_activation": "relu"
                }
            }
        }
    },
    "pre_encode_feedforward": {
        "input_dim": 896,
        "num_layers": 1,
        "hidden_dims": [896],
        "activations": ["relu"],
        "dropout": [0.25]
    },
    "integrator": {
      "type": "lstm",
      "input_size": 384,
      "hidden_size": 100,
      "num_layers": 1,
      "bidirectional": true
    },
    "embedding_dropout": 0.25,
    "integrator_dropout": 0.1,
    "encoder": {
      "type": "lstm",
      "input_size": 896,
      "hidden_size": 128
    },
     "output_layer": {
        "input_dim": 800,
        "num_layers": 3,
        "output_dims": [400, 200, 3],
        "pool_sizes": 4,
        "dropout": [0.2, 0.3, 0.0]
    }
  },
  "iterator": {
    "type": "bucket",
    "batch_size": 8,
    "sorting_keys": [["tokens", "num_tokens"]]
  },
  "trainer": {
    "num_epochs": 50,
    "patience": 5,
    "optimizer": {
      "type": "adam",
      "lr": 0.0001
    }
  }
}
